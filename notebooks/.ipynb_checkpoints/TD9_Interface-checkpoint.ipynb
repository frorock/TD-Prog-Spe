{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "ROOT = Path.cwd().resolve()          # .../TD_PROGSPE_PYTHON/notebooks\n",
    "SRC  = (ROOT.parent / \"src\").resolve()\n",
    "DATA = (ROOT.parent / \"data\").resolve()\n",
    "\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "from td8_discours import read_discours_tsv, parse_date_safe, split_into_sentences\n",
    "from Corpus import Corpus\n",
    "from Document import Document\n",
    "from SearchEngine import SearchEngine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34481f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = DATA / \"discours_US.csv\"\n",
    "df_raw = read_discours_tsv(csv_path)\n",
    "\n",
    "Corpus.reset_singleton()\n",
    "corpus = Corpus(\"Corpus TD9 - Discours US\")\n",
    "\n",
    "docs_rows = []  # pour analyses TD9 (comparaison / temps)\n",
    "\n",
    "for _, row in df_raw.iterrows():\n",
    "    auteur = str(row.get(\"speaker\", \"Unknown\")).strip() or \"Unknown\"\n",
    "    titre  = str(row.get(\"descr\", \"Discours\")).strip() or \"Discours\"\n",
    "    date   = parse_date_safe(row.get(\"date\", None))\n",
    "    url    = str(row.get(\"link\", \"\")).strip()\n",
    "    text   = row.get(\"text\", \"\")\n",
    "\n",
    "    for sent in split_into_sentences(text):\n",
    "        corpus.add_document(Document(titre=titre, auteur=auteur, date=date, url=url, texte=sent))\n",
    "        docs_rows.append({\"auteur\": auteur, \"date\": date, \"texte\": sent, \"url\": url, \"titre\": titre})\n",
    "\n",
    "se = SearchEngine(corpus)\n",
    "df_docs = pd.DataFrame(docs_rows)\n",
    "\n",
    "print(\"✅ Corpus:\", corpus)\n",
    "df_docs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e601e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = {\n",
    "    \"the\",\"a\",\"an\",\"and\",\"or\",\"to\",\"of\",\"in\",\"on\",\"for\",\"with\",\"is\",\"are\",\"was\",\"were\",\n",
    "    \"be\",\"been\",\"it\",\"that\",\"this\",\"as\",\"at\",\"by\",\"from\",\"we\",\"you\",\"they\",\"i\",\"our\",\n",
    "    \"your\",\"their\",\"not\",\"but\",\"will\",\"would\",\"can\",\"could\",\"should\",\"my\",\"me\",\"us\"\n",
    "}\n",
    "\n",
    "def tokenize(text: str):\n",
    "    text = (text or \"\").lower()\n",
    "    words = re.findall(r\"[a-z']+\", text)\n",
    "    return [w for w in words if len(w) >= 3 and w not in STOPWORDS]\n",
    "\n",
    "def tf_counts(sub_df: pd.DataFrame):\n",
    "    c = {}\n",
    "    for t in sub_df[\"texte\"].astype(str):\n",
    "        for w in tokenize(t):\n",
    "            c[w] = c.get(w, 0) + 1\n",
    "    return c\n",
    "\n",
    "def top_distinctive_words(df_docs, a1, a2, top_n=20):\n",
    "    d1 = df_docs[df_docs[\"auteur\"] == a1]\n",
    "    d2 = df_docs[df_docs[\"auteur\"] == a2]\n",
    "    c1 = tf_counts(d1)\n",
    "    c2 = tf_counts(d2)\n",
    "\n",
    "    # score simple: fréquence relative (diff)\n",
    "    n1 = sum(c1.values()) or 1\n",
    "    n2 = sum(c2.values()) or 1\n",
    "\n",
    "    all_words = set(c1) | set(c2)\n",
    "    scored = []\n",
    "    for w in all_words:\n",
    "        s = (c1.get(w,0)/n1) - (c2.get(w,0)/n2)\n",
    "        scored.append((w, s, c1.get(w,0), c2.get(w,0)))\n",
    "\n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "    return pd.DataFrame(scored[:top_n], columns=[\"mot\", \"score(a1-a2)\", \"tf_a1\", \"tf_a2\"])\n",
    "\n",
    "def word_over_time(df_docs, word: str, auteur=None):\n",
    "    word = word.lower().strip()\n",
    "    d = df_docs.copy()\n",
    "    if auteur and auteur != \"ALL\":\n",
    "        d = d[d[\"auteur\"] == auteur]\n",
    "\n",
    "    d = d.dropna(subset=[\"date\"])\n",
    "    d[\"month\"] = pd.to_datetime(d[\"date\"]).dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "    # compter occurrences par phrase (simple)\n",
    "    def count_word(t):\n",
    "        return sum(1 for w in tokenize(t) if w == word)\n",
    "\n",
    "    d[\"cnt\"] = d[\"texte\"].astype(str).map(count_word)\n",
    "    out = d.groupby(\"month\")[\"cnt\"].sum().reset_index()\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widgets communs\n",
    "authors = sorted(df_docs[\"auteur\"].unique().tolist())\n",
    "authors_all = [\"ALL\"] + authors\n",
    "\n",
    "# --- Onglet 1 : Recherche ---\n",
    "q = widgets.Text(value=\"climate change\", description=\"Query:\", layout=widgets.Layout(width=\"70%\"))\n",
    "topk = widgets.IntSlider(value=10, min=1, max=50, step=1, description=\"TopK:\", continuous_update=False)\n",
    "btn_search = widgets.Button(description=\"Search\", button_style=\"success\")\n",
    "out_search = widgets.Output()\n",
    "\n",
    "def on_search(_):\n",
    "    with out_search:\n",
    "        clear_output()\n",
    "        res = se.search(q.value, top_k=int(topk.value), show_progress=False)\n",
    "        display(res)\n",
    "\n",
    "btn_search.on_click(on_search)\n",
    "tab_search = widgets.VBox([widgets.HBox([q, btn_search]), topk, out_search])\n",
    "\n",
    "# --- Onglet 2 : Comparaison auteurs ---\n",
    "a1 = widgets.Dropdown(options=authors, value=authors[0], description=\"A1:\")\n",
    "a2 = widgets.Dropdown(options=authors, value=authors[1] if len(authors)>1 else authors[0], description=\"A2:\")\n",
    "topn = widgets.IntSlider(value=20, min=5, max=50, step=5, description=\"TopN:\", continuous_update=False)\n",
    "btn_cmp = widgets.Button(description=\"Compare\", button_style=\"primary\")\n",
    "out_cmp = widgets.Output()\n",
    "\n",
    "def on_compare(_):\n",
    "    with out_cmp:\n",
    "        clear_output()\n",
    "        df_cmp = top_distinctive_words(df_docs, a1.value, a2.value, top_n=int(topn.value))\n",
    "        display(df_cmp)\n",
    "\n",
    "btn_cmp.on_click(on_compare)\n",
    "tab_cmp = widgets.VBox([widgets.HBox([a1, a2, btn_cmp]), topn, out_cmp])\n",
    "\n",
    "# --- Onglet 3 : Évolution temporelle ---\n",
    "w_word = widgets.Text(value=\"climate\", description=\"Word:\")\n",
    "w_auth = widgets.Dropdown(options=authors_all, value=\"ALL\", description=\"Author:\")\n",
    "btn_time = widgets.Button(description=\"Plot\", button_style=\"warning\")\n",
    "out_time = widgets.Output()\n",
    "\n",
    "def on_time(_):\n",
    "    with out_time:\n",
    "        clear_output()\n",
    "        serie = word_over_time(df_docs, w_word.value, auteur=None if w_auth.value==\"ALL\" else w_auth.value)\n",
    "        display(serie)\n",
    "        plt.figure()\n",
    "        plt.plot(serie[\"month\"], serie[\"cnt\"])\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title(f\"Occurrences de '{w_word.value}' (par mois) - {w_auth.value}\")\n",
    "        plt.xlabel(\"Mois\")\n",
    "        plt.ylabel(\"Occurrences\")\n",
    "        plt.show()\n",
    "\n",
    "btn_time.on_click(on_time)\n",
    "tab_time = widgets.VBox([widgets.HBox([w_word, w_auth, btn_time]), out_time])\n",
    "\n",
    "tabs = widgets.Tab(children=[tab_search, tab_cmp, tab_time])\n",
    "tabs.set_title(0, \"Search\")\n",
    "tabs.set_title(1, \"Compare\")\n",
    "tabs.set_title(2, \"Time\")\n",
    "display(tabs)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
